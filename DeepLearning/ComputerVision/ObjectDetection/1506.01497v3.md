# Faster R-CNN

## Introduction

* Time: 2015.06
* Author: Shaoqing Ren 等

Faster R-CNN (以下简称本算法)是一个两阶段基于Anchor的目标检测框架，该框架采用Region Proposal Network (RPN) 代替了Fast R-CNN和SPPnet中使用的Region Proposal Algorithm。在提升精度的同时，大大加快了目标检测的速度。本文着重介绍RPN网络和Bbox Head。

![Faster R-CNN model](./../../../Resource/Pictures/faster-rcnn.svg)

## Detail

### CNN模块

CNN模块是整个模型的主干网络，原始论文中使用VGG，现也可采用ResNet和MobileNet等更出色的主干网络。

* 输入：原始图片
* 输出：经过CNN模块提取的特征图(Feature Map)

### RPN

* **输入**：经过CNN的feature map，假设其维度为$(C_1, H, W)$
* 经过一个$n\times n$的卷积（paper中$n=3$），将特征图压缩成$(C_2, H, W)$
* 此时的特征图的每一个像素对应着事先设置好的k个不同大小和长宽比例的anchor的中心，所以整张feature map上会生成$HWk$个anchor
* 将每个像素对应的$C2$维度的向量输入进两个分支中：
  * 分类分支：输出每个anchor中是否包含objects，由$1\times 1$卷积实现，输出维度$(2k, H, W)$
  * 回归分支：输出每个anchor对应的边界框坐标，总共$k$个regressor，分别负责k种不同anchor的坐标回归，输出维度$(4k, H, W)$
* 采用NMS非极大值抑制（详见[Basic Concepts](../Basic%20Concepts.md)）等过滤手段，保留部分RPN生成的预测框
* **输出**：预测框生成的proposal

#### 训练过程

##### 监督信息获取

在训练过程中，首先需要告诉分类分支哪些anchor是包含object的（正样本），哪些anchor只包含background（负样本），这样才能训练此分类器。同时，为了训练回归分支，同样需要为每一个anchor分配一个需要回归的目标。

正负样本的分类标准如下：

* 正样本：
  * (i) 与某一真实框IoU最大的Anchor
  * (ii) 与任意真实框IoU大于0.7的Anchor
* 负样本：
  * 与所有真实框的IoU都小于0.3的Anchor

对于正样本来说，如果只有(ii)则可能会导致挑不出正样本。在挑选正样本的过程中，也同时为每一个anchor指定了其对应的真实框，真实框的坐标用来训练回归分支。

按照上述分类标准，负样本的数量会远远大于正样本的数量，所以为了解决类别不平衡问题，还制定了如下的采样规则：

* 共采样256个样本
* 从正样本中随机采样，采样个数不超过128个
* 从负样本中随机采样，补齐256个样本

##### Loss函数

$$ Loss({p_i}, {t_i}) = \frac{1}{N_{cls}}\sum_iL_{cls}(p_i, p_i^\ast )+\lambda \frac{1}{N_{reg}}\sum_ip_i^\ast L_{reg}(t_i, t_i^\ast) $$

$$ L_{reg}(t_i, t_i^\ast)=\sum_{j\in{x, y, w, h}}{\rm smooth}_{L1} (t_{ji}-t_{ji}^\ast) $$

其中$p_i$是分类分支预测的anchor中是否包含objection的概率。$p_i^*$是anchor对应的label，正样本为1，负样本为0.

$$ t_i = [t_{xi}, t_{yi}, t_{wi}, t_{hi}] $$

$$ t_i^\ast = [t_{xi}^\ast, t_{yi}^\ast, t_{wi}^\ast, t_{hi}^\ast] $$

$$t_x = (x-x_a)/w_a, t_y = (y-y_a)/h_a, t_2=\log(w/w_a),t_h=\log(h/h_a)$$

$$t_x^* = (x^\ast-x_a)/w_a, t_y = (y^\ast-y_a)/h_a, t_2=\log(w^\ast/w_a),t_h=\log(h^\ast/h_a)$$

$t_i$代表坐标向量，$ t_i^\ast $是真实框的坐标向量。$ x, y, w, h $分别代表边框中心的坐标和宽度长度。$ x, x_a, x^\ast $分别代表预测框，anchor，真实框。

$${\rm smooth}_{L_1}(x)=\left \lbrace
    \begin{aligned}
    0.5x^2, |x|<1\newline
    |x|-0.5, \rm otherwise
    \end{aligned}
    \right.$$

smooth损失在预测和信息差别过大时，梯度不至于过大；差别很小时，梯度足够小。

##### anchor的筛选

在对anchor进行采样前，会忽略所有和图片边界有交叉的anchor。

在测试过程中，在对每个anchor进行预测前，会将和图片边界有交叉的anchor剪裁到图片边界中。

### BBox Head

* **输入：** 经过RoI之后的子特征图，假设有512个proposal，维度为$(512, 1024, 14, 14)$
* 通过一系列卷积和Pooling将特征图从$14\times 14$压缩到$1\times 1$，此时维度为$(512, 2048, 14, 14)$
* 进行多分类和回归，输出维度分别为$(512, class)$, $(512, 4\times class)$，其中回归分支的输出只在分类结果对应的4个位置生成坐标预测结果，其余位置全部为0，也就是说在$4\times class$的向量中，只会4个连续的位置存放坐标。
* 接下来就是把分类和回归结果结合RoI信息进行解码，再次经过NMS，得到最终的预测结果

#### 训练阶段

##### 监督信息获取

与RPN类似，需要提供预测的监督信息。

正负样本采样标准：

* 正样本：IoU>0.5
* 负样本：IoU<0.5

为了防止没有正样本，实际采样过程中真实框也会参与采样。采样规则：

* 共采样512个样本
* 从正样本中随机采样，采样个数不超过128个
* 从负样本中随机采样，补齐512个样本

##### Loss

同样是分类分支和回归分支损失的加权和，BBox Head的损失会和RPN的损失相加，得到整个网络的Loss。

## 缺点

1. RoI Pooling的缺点，详见[Basic Concepts](../Basic%20Concepts.md)
2. 经过多次卷积和pooling之后导致特征图的分辨率较小，导致小物体检测效果不佳
3. 非极大值抑制本身的过滤对于遮挡物体不是特别友好，本身属于两个物体的候选框有可能因为非极大值抑制而被过滤为1个，造成漏检
4. 在 RPN 及 RCNN 部分，都是通过超参数来限制正负样本的数量，以保证正负样本的均衡。而对于不同任务与数据，这种正负样本均衡方法不一定是最有效的
5. 虽然精度较高，但是速度仍然无法达到实时检测
